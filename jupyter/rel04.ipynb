{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REL 4: How are you monitoring AWS resources?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics, logs and events are monitored. Monitoring is invaluable for learning and improving systems, especially as architectures are decomposed into fine-grained services and becomes more complex. Monitoring provides not only the visibility to ensure that resources in healthy utilization, but a history to understand the behavior of normal and abnormal conditions. \n",
    "\n",
    "Amazon CloudWatch is the central monitoring service at AWS, it will manage these three types of monitoring resources: Metrics, Events and logs.\n",
    "\n",
    "Metrics are time series recorded from monitoring both AWS resources and custom resources. CloudWatch automatically aggregates and stores metric data, but resolution and availability of metric data changes with time:\n",
    "\n",
    "Data points period\tAvailable for\n",
    "less than 60 seconds\t3 hours (high-resolution custom metrics)\n",
    "60 seconds (1 minute)\t15 days\n",
    "300 seconds (5 minute)\t63 days \n",
    "3600 seconds (1 hour)\t455 days (15 months)\n",
    "\n",
    "Aggregating and expiring data automatically makes metric storage extremely efficient with fine visibility into the present and aggregate history of measurements. As the documentation clarifies:\n",
    "\n",
    "“For example, if you collect data using a period of 1 minute, the data remains available for 15 days with 1-minute resolution. After 15 days this data is still available, but is aggregated and is retrievable only with a resolution of 5 minutes. After 63 days, the data is further aggregated and is available with a resolution of 1 hour. If you need availability of metrics longer than these periods, you can use the GetMetricStatistics API to retrieve the datapoints for offline or different storage.”\n",
    "\n",
    "CloudWatch serves metric data as statistics over different aggregation periods. Each statistic will provide a different perspective of the behavior of the metric and its alarms. Think of them as lenses into the system, using the correct one to detect and correct each circumstance of interest. The available statistics are Average, Minimum and Maximum, Sum, Count and Percentiles \n",
    "\n",
    "The average metric is the widely used arithmetic mean, the sum of values divided by the number of samples, computed automatically by CloudWatch. The key to using the average statistic is understanding its variability, especially in small environments. Consider for example the average CPU Utilization of 4 application servers with different loads. \n",
    "The variance will be so high that the metric is not stable enough to create an alarm or even interpret. The more data and the more consistent the resource utilization, the more reliable the average will be.\n",
    "\n",
    "Maximum and minimum are straightforward, but the latter is particularly useful for monitoring resource exhaustion. When “available memory”, “available threads in pool”, “available connections in pool”, or any other resource availability reaches zero, it is probably a cause for alarm. The Sum statistic is useful to determine total volumes, for example the sum of requests to a load balancer or total duration of lambda executions. The Sample Count tells simply how many data points were aggregated, but the interesting thing is sampling rate is usually constant. Variations in sample counts can indicate network partitioning and other issues.\n",
    "\n",
    "Percentiles are helpful to understand the variation of metrics and catch outliers that would be hard to see using averages or other statistics. Specially with Latency, it can reveal garbage collections or other circumstances that affect only a few of the requests in the higher percentiles.\n",
    "\n",
    "By default, CloudWatch records metrics related to AWS resources, such as EC2 instance CPU utilization, ELB latency, count of S3 objects and so on. Custom metrics can be created for resources that CloudWatch can’t probe from the outside. Those metrics can be anything, from operational metrics such as the available threads in an application server thread pool to business metrics, such as volume of sales. Any kind of measurement can be sent to CloudWatch using the PutMetricData API. This is very useful to create alarms based on resources not managed by AWS, such as application server thread pool and connections pool. It can also monitor business metrics, such as transaction volumes and literally any quantity. \n",
    "\n",
    "Logs are grouped streams of text emitted from application execution. The metrics and events provide a limited overview of system behavior, but logs can reveal the true application circumstances from the inside. Having them all in CloudWatch helps to correlate data to form a better picture of events and how to handle them. Another key feature of CloudWatch logs is to trigger lambda functions in response to text, alarming on interesting application conditions, such as exceptions or even simple variable dumps.\n",
    "\n",
    "Events notifies customers of events occurred in their AWS resources or custom events. CloudWatch events can notify several interesting events, such as instance creation, auto scaling group changes or even S3 object level operations.\n",
    "\n",
    "CloudWatch Events is also widely used for automation as schedules can be defined as event sources. This lets you execute lambda functions in a specific schedule and taking virtually any action without running your own job server.\n",
    "\n",
    "Responses are continuously automated. Coding the detection and responses to system operation events is the mantra for improving reliability. Any software team can easily speak about technical debt and the issues it causes, from those that customers often hit to those that developers hope not to happen. Prioritizing and automating the handling of changes, expected and unexpected, is a way to gradually and continuously improve reliability.\n",
    "\n",
    "The more frequent and risky a change is, the earlier it should be automated, so application deployment is clearly the first target. But it goes much further: resource provisioning, configuration changes, failover, substitution, decommissioning...  all can be automated so that precious human attention is dedicated only to the issues intriguing enough to require it. Or those have not been automated yet.\n",
    "\n",
    "Leverage third-party tools. Monitoring is a rich partner ecosystem with additional features that goes from collection to visualization and predictive analytics. Visit the monitoring section of the AWS Marketplace for a list of partner tools to improve monitoring analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
